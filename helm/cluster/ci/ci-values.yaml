global:
  managementCluster: giantmc
  metadata:
    name: awesome
    organization: giantswarm
    description: "Awesome Giant Swarm cluster"
    preventDeletion: true
    labels:
      some-cluster-label: label-1
      another-cluster-label: label-2
    annotations:
      important-cluster-value: "1000"
      robots-need-this-in-the-cluster: "eW91IGNhbm5vdCByZWFkIHRoaXMsIGJ1dCByb2JvdHMgY2FuCg=="
  connectivity:
    baseDomain: example.gigantic.io
    vpcMode: private
    proxy:
      enabled: true
      httpProxy: http://proxy.giantswarm.io
      httpsProxy: https://proxy.giantswarm.io
      noProxy: "proxy1.example.com,proxy2.example.com"
  controlPlane:
    customNodeTaints:
    - key: you
      value: shall
      effect: NoExecute
    oidc:
      clientId: hello
      groupsClaim: groupsClaim
      issuerUrl: https://giantswarm.io
      usernameClaim: usernameClaim
      caPem: "..."
    replicas: 3
  nodePools:
    def00:
      replicas: 3
      labels:
        nodepool-workload-type: ai
      annotations:
        for-robots-in-nodepool: "cm9ib3RzIGFyZSBvcGVyYXRpbmcgb24gdGhpcyBub2RlIHBvb2wK"
      nodeLabels:
        workload-type: ai
      nodeTaints:
      - key: supernodepool
        value: hello
        effect: NoSchedule
    verybignodepool-1234:
      replicas: 100
      nodeLabels:
        workload-type: robots
  components:
    containerd:
      containerRegistries:
        docker.io:
        - endpoint: registry-1.docker.io
          credentials:
            username: giantswarm
            password: super_secret_password
        - endpoint: giantswarm.azurecr.io
internal:
  advancedConfiguration:
    cgroupsv1: true
    controlPlane:
      apiServer:
        bindPort: 6443
        etcdPrefix: giantswarm.io
        extraArgs:
          allow-privileged: false
          authorization-webhook-version: v1beta1
          delete-collection-workers: 2
          min-request-timeout: 600
        extraCertificateSANs:
        - this-is-extra-cert-san.giantswarm.io
        - another-extra-cert-san.giantswarm.io
    files:
    - path: /etc/hello/any/node/stuff.yaml
      permissions: "0644"
      contentFrom:
        secret:
          name: cluster-super-secret
          key: node-stuff
providerIntegration:
  provider: aws
  bastion:
    kubeadmConfig:
      ignition:
        containerLinuxConfig:
          additionalConfig:
            systemd:
              units:
              - name: example1-bastion.service
                enabled: false
                mask: false
                contents:
                  unit:
                    description: "Bastion example 1"
                dropins:
                - name: hello-bastion.conf
                  contents: |
                    # Contents goes here
      preKubeadmCommands:
      - sleep infinity
  clusterAnnotationsTemplateName: "cluster.test.providerIntegration.connectivity.annotations"
  connectivity:
    proxy:
      noProxy:
        value:
        - elb.amazonaws.com
        - 169.254.169.254
        templateName: "cluster.test.internal.kubeadm.proxy.anotherNoProxyList"
  controlPlane:
    kubeadmConfig:
      clusterConfiguration:
        apiServer:
          additionalAdmissionPlugins:
          - AlwaysPullImages
          - PodSecurityPolicy
          apiAudiences:
            templateName: "cluster.test.kubeadmControlPlane.kubeadmConfigSpec.clusterConfiguration.apiServer.apiAudiences"
          featureGates:
          - name: CronJobTimeZone
            enabled: true
          - name: DownwardAPIHugePages
            enabled: false
          - name: TTLAfterFinished
            enabled: true
          serviceAccountIssuer:
            clusterDomainPrefix: irsa
        etcd:
          initialCluster: "default=http://localhost:2380"
          initialClusterState: "existing"
          extraArgs:
            max-snapshots: 3
            snapshot-count: 50000
          experimental:
            peerSkipClientSanVerification: true
      files:
      - path: /etc/hello/control-plane/node/stuff.yaml
        permissions: "0644"
        contentFrom:
          secret:
            name: cluster-super-secret-control-plane
            key: node-stuff
      ignition:
        containerLinuxConfig:
          additionalConfig:
            systemd:
              units:
              - name: var-lib-etcd.mount
                enabled: true
                mask: false
                contents:
                  unit:
                    description: etcd volume
                    defaultDependencies: false
                  install:
                    wantedBy:
                    - local-fs-pre.target
                  mount:
                    what: /dev/disk/by-label/etcd
                    where: /var/lib/etcd
                    type: xfs
              - name: example2-control-plane.service
                enabled: false
                mask: false
                dropins:
                - name: hello1-control-plane.conf
                  contents: |
                    # Multi-line
                    # contents goes here
                - name: hello2-control-plane.conf
                  contents: |
                    # Multi-line
                    # contents goes here
            storage:
              filesystems:
              - name: etcd
                mount:
                  device: /dev/xvdc
                  wipeFilesystem: true
                  label: etcd
                  format: xfs
              - name: containerd
                mount:
                  device: /dev/xvdd
                  wipeFilesystem: true
                  label: containerd
                  format: xfs
              - name: kubelet
                mount:
                  device: /dev/xvde
                  wipeFilesystem: true
                  label: kubelet
                  format: xfs
              directories:
              - path: /var/lib/kubelet/temporary/stuff/control-plane
                overwrite: true
                filesystem: kubelet
                mode: 750
                user:
                  id: 12345
                  name: giantswarm
                group:
                  id: 23456
                  name: giantswarm
      preKubeadmCommands:
      - echo "hello control plane before kubeadm"
      - echo "cluster control plane before kubeadm"
      postKubeadmCommands:
      - echo "hello control plane after kubeadm"
      - echo "cluster control plane after kubeadm"
    resources:
      infrastructureMachineTemplate:
        group: infrastructure.cluster.x-k8s.io
        version: v1beta1
        kind: AWSMachineTemplate
      infrastructureMachineTemplateSpecTemplateName: "cluster.internal.test.controlPlane.machineTemplate.spec"
  components:
    systemd:
      timesyncd:
        ntp:
        - 169.254.169.123
  hashSalt: salty-1
  kubeadmConfig:
    ignition:
      containerLinuxConfig:
        additionalConfig:
          systemd:
            units:
            - name: var-lib-kubelet.mount
              enabled: true
              mask: false
              contents:
                unit:
                  description: kubelet volume
                  defaultDependencies: false
                install:
                  wantedBy:
                  - local-fs-pre.target
                mount:
                  what: /dev/disk/by-label/kubelet
                  where: /var/lib/kubelet
                  type: xfs
            - name: var-lib-containerd.mount
              enabled: true
              mask: false
              contents:
                unit:
                  description: containerd volume
                  defaultDependencies: false
                install:
                  wantedBy:
                  - local-fs-pre.target
                mount:
                  what: /dev/disk/by-label/containerd
                  where: /var/lib/containerd
                  type: xfs
            - name: example2.service
              enabled: false
              mask: false
              dropins:
              - name: hello1.conf
                contents: |
                  # Multi-line
                  # contents goes here
              - name: hello2.conf
                contents: |
                  # Multi-line
                  # contents goes here
          storage:
            directories:
            - path: /var/lib/kubelet/temporary/stuff
              overwrite: true
              filesystem: kubelet
              mode: 750
              user:
                id: 12345
                name: giantswarm
              group:
                id: 23456
                name: giantswarm
    preKubeadmCommands:
    - echo "hello all nodes before kubeadm"
    - echo "all cluster nodes before kubeadm"
    postKubeadmCommands:
    - echo "hello all nodes after kubeadm"
    - echo "all cluster nodes after kubeadm"
  kubernetesVersion: 1.24.10
  pauseProperties:
    global.connectivity.vpcMode: private
  resourcesApi:
    clusterResourceEnabled: true
    controlPlaneResourceEnabled: true
    machinePoolResourcesEnabled: true
    machineHealthCheckResourceEnabled: true
    bastionResourceEnabled: true
    infrastructureCluster:
      group: infrastructure.cluster.x-k8s.io
      version: v1beta1
      kind: AWSCluster
    nodePoolKind: MachinePool
    infrastructureMachinePool:
      group: infrastructure.cluster.x-k8s.io
      version: v1beta1
      kind: AWSMachinePool
    bastion:
      infrastructureMachineTemplate:
        group: infrastructure.cluster.x-k8s.io
        version: v1beta1
        kind: AWSMachineTemplate
      infrastructureMachineTemplateSpecTemplateName: "cluster.test.bastion.machineTemplate.spec"
  teleport:
    enabled: true
  workers:
    kubeadmConfig:
      files:
      - path: /etc/hello/worker/node/stuff.yaml
        permissions: "0644"
        contentFrom:
          secret:
            name: cluster-super-secret-worker
            key: node-stuff
      ignition:
        containerLinuxConfig:
          additionalConfig:
            systemd:
              units:
              - name: var-lib-workload.mount
                enabled: true
                mask: false
                contents:
                  unit:
                    description: workload volume
                    defaultDependencies: false
                  install:
                    wantedBy:
                    - local-fs-pre.target
                  mount:
                    what: /dev/disk/by-label/workload
                    where: /var/lib/workload
                    type: xfs
              - name: example2-workers.service
                enabled: false
                mask: false
                dropins:
                - name: hello1-workers.conf
                  contents: |
                    # Multi-line
                    # contents goes here
                - name: hello2-workers.conf
                  contents: |
                    # Multi-line
                    # contents goes here
            storage:
              directories:
              - path: /var/lib/kubelet/temporary/stuff/workers
                overwrite: true
                filesystem: kubelet
                mode: 750
                user:
                  id: 12345
                  name: giantswarm
                group:
                  id: 23456
                  name: giantswarm
      preKubeadmCommands:
      - echo "hello workers before kubeadm"
      - echo "cluster workers before kubeadm"
      postKubeadmCommands:
      - echo "hello workers after kubeadm"
      - echo "cluster workers after kubeadm"
